{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e3e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "#Langsmith tracking\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACKING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e7569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001D940EE0BD0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D940EE24D0> root_client=<openai.OpenAI object at 0x000001D940080210> root_async_client=<openai.AsyncOpenAI object at 0x000001D940EE0D50> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model = \"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaaefb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a subset of artificial intelligence systems designed to create new content, such as text, images, music, or even complex data structures. Unlike traditional AI models that primarily focus on classifying or predicting data, generative AI systems use deep learning techniques, such as neural networks, to generate novel outputs based on the data they've been trained on.\\n\\nSome popular examples of generative AI include:\\n\\n1. **Text Generation**: Models like OpenAI's GPT (Generative Pre-trained Transformer) which can generate human-like text based on prompts.\\n\\n2. **Image Generation**: Tools like DALL-E or Midjourney that can create unique images from textual descriptions.\\n\\n3. **Music and Audio Generation**: AI systems capable of composing original music or generating synthetic voices that imitate human speech.\\n\\n4. **Code Generation**: AI models that assist in writing or suggesting code, improving software development efficiency.\\n\\nIn many cases, generative AI can assist in creative processes, automate workflows, and provide innovative solutions in various industries, such as entertainment, marketing, and technology development. However, as with all technologies, it also raises ethical and practical considerations around issues like copyright, authenticity, and potential misuse.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 242, 'prompt_tokens': 11, 'total_tokens': 253, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_cbf1785567', 'id': 'chatcmpl-CW8l7362eveGadyTONFjfcUJll6f1', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--eec678f8-aa80-467d-92d1-00ebbd3513e9-0' usage_metadata={'input_tokens': 11, 'output_tokens': 242, 'total_tokens': 253, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## Input and get response\n",
    "result = llm.invoke(\"What is gen Ai\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d8abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ffd164e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Chatprompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "\n",
    "    [(\"system\",\"You are an expert AI Engineer. Provide me answers based on the question\"),\n",
    "     (\"user\",\"{input}\"),\n",
    "     \n",
    "     ]\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7726a8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangSmith is a developer toolset and platform offered by LangChain, designed to enhance the building, testing, debugging, and monitoring of applications that use large language models (LLMs). It aims to streamline the development workflow for applications that leverage LLMs and chains, providing tools that allow developers to effectively manage, refine, and troubleshoot their language model applications.\\n\\nKey features of LangSmith typically include:\\n\\n1. **Experiment Tracking**: Allows developers to manage and compare different runs and configurations easily, aiding in the iterative development process.\\n\\n2. **Debugging Aids**: Provides insights and tools for identifying and fixing issues within language model-based workflows and chains.\\n\\n3. **Performance Monitoring**: Offers real-time monitoring capabilities to track the performance and usage of applications, ensuring efficiency and reliability.\\n\\n4. **Data Management**: Facilitates handling and organizing the data used for testing and refining LLM-based applications.\\n\\nLangSmith can be particularly valuable in applications involving complex workflows or those requiring tight integration with other services. However, for the latest and specific updates about LangSmith, it would be advisable to check the official LangChain website or their latest documentation.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 230, 'prompt_tokens': 33, 'total_tokens': 263, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_65564d8ba5', 'id': 'chatcmpl-CW8sFGXQmoTDQMuImBYTfBo7O52Xe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--6f51c392-3b6f-46c6-a1e1-8fd64e72c79f-0' usage_metadata={'input_tokens': 33, 'output_tokens': 230, 'total_tokens': 263, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Chain\n",
    "chain = prompt|llm\n",
    "response = chain.invoke({\"input\":\"Can you tell me about langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5c93d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a development toolkit offered by LangChain that focuses on making it easier for developers to build, test, and evaluate language model applications. It provides a suite of tools designed to streamline the development process and enhance the performance and accuracy of applications utilizing language models.\n",
      "\n",
      "Key features of Langsmith include:\n",
      "\n",
      "1. **Monitoring**: Langsmith offers capabilities to monitor the performance of language models, helping developers understand how their models are functioning over time and in different scenarios.\n",
      "\n",
      "2. **Tracing**: It provides mechanisms to trace the execution of language model applications, enabling developers to identify bottlenecks, errors, or unexpected behaviors in their applications.\n",
      "\n",
      "3. **Evaluation**: Langsmith includes tools to evaluate language models' outputs against expected results or benchmarks, allowing for more rigorous testing and refinement of applications.\n",
      "\n",
      "4. **Dataset Management**: Developers can manage and utilize datasets more efficiently within Langsmith, which is crucial for training and evaluating language models effectively.\n",
      "\n",
      "Overall, Langsmith aims to enhance the development lifecycle of language model applications, from building and optimizing to deploying and maintaining them in production environments.\n"
     ]
    }
   ],
   "source": [
    "## String output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "response = chain.invoke({\"input\":\"Can you tell me about langsmith?\"})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlbootcamp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
